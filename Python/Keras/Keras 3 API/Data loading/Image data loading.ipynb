{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data loading\n",
    "https://keras.io/api/data_loading/image/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image_dataset_from_directory function\n",
    "\n",
    "keras.utils.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "Generates a tf.data.Dataset from image files in a directory.\n",
    "\n",
    "If your directory structure is:\n",
    "\n",
    "main_directory/\n",
    "...class_a/\n",
    "......a_image_1.jpg\n",
    "......a_image_2.jpg\n",
    "...class_b/\n",
    "......b_image_1.jpg\n",
    "......b_image_2.jpg\n",
    "\n",
    "Then calling image_dataset_from_directory(main_directory, labels='inferred') will return a tf.data.Dataset that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\n",
    "\n",
    "Supported image formats: .jpeg, .jpg, .png, .bmp, .gif. Animated gifs are truncated to the first frame.\n",
    "\n",
    "Arguments\n",
    "\n",
    "    directory: Directory where the data is located. If labels is \"inferred\", it should contain subdirectories, each containing images for a class. Otherwise, the directory structure is ignored.\n",
    "    labels: Either \"inferred\" (labels are generated from the directory structure), None (no labels), or a list/tuple of integer labels of the same size as the number of image files found in the directory. Labels should be sorted according to the alphanumeric order of the image file paths (obtained via os.walk(directory) in Python).\n",
    "    label_mode: String describing the encoding of labels. Options are:\n",
    "        \"int\": means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "        \"categorical\" means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "        \"binary\" means that the labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy).\n",
    "        None (no labels).\n",
    "    class_names: Only valid if labels is \"inferred\". This is the explicit list of class names (must match names of subdirectories). Used to control the order of the classes (otherwise alphanumerical order is used).\n",
    "    color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Whether the images will be converted to have 1, 3, or 4 channels. Defaults to \"rgb\".\n",
    "    batch_size: Size of the batches of data. Defaults to 32. If None, the data will not be batched (the dataset will yield individual samples).\n",
    "    image_size: Size to resize images to after they are read from disk, specified as (height, width). Since the pipeline processes batches of images that must all have the same size, this must be provided. Defaults to (256, 256).\n",
    "    shuffle: Whether to shuffle the data. Defaults to True. If set to False, sorts the data in alphanumeric order.\n",
    "    seed: Optional random seed for shuffling and transformations.\n",
    "    validation_split: Optional float between 0 and 1, fraction of data to reserve for validation.\n",
    "    subset: Subset of the data to return. One of \"training\", \"validation\", or \"both\". Only used if validation_split is set. When subset=\"both\", the utility returns a tuple of two datasets (the training and validation datasets respectively).\n",
    "    interpolation: String, the interpolation method used when resizing images. Supports \"bilinear\", \"nearest\", \"bicubic\", \"area\", \"lanczos3\", \"lanczos5\", \"gaussian\", \"mitchellcubic\". Defaults to \"bilinear\".\n",
    "    follow_links: Whether to visit subdirectories pointed to by symlinks. Defaults to False.\n",
    "    crop_to_aspect_ratio: If True, resize the images without aspect ratio distortion. When the original aspect ratio differs from the target aspect ratio, the output image will be cropped so as to return the largest possible window in the image (of size image_size) that matches the target aspect ratio. By default (crop_to_aspect_ratio=False), aspect ratio may not be preserved.\n",
    "    pad_to_aspect_ratio: If True, resize the images without aspect ratio distortion. When the original aspect ratio differs from the target aspect ratio, the output image will be padded so as to return the largest possible window in the image (of size image_size) that matches the target aspect ratio. By default (pad_to_aspect_ratio=False), aspect ratio may not be preserved.\n",
    "    data_format: If None uses keras.config.image_data_format() otherwise either 'channel_last' or 'channel_first'.\n",
    "    verbose: Whether to display number information on classes and number of files found. Defaults to True.\n",
    "\n",
    "Returns\n",
    "\n",
    "A tf.data.Dataset object.\n",
    "\n",
    "    If label_mode is None, it yields float32 tensors of shape (batch_size, image_size[0], image_size[1], num_channels), encoding images (see below for rules regarding num_channels).\n",
    "    Otherwise, it yields a tuple (images, labels), where images has shape (batch_size, image_size[0], image_size[1], num_channels), and labels follows the format described below.\n",
    "\n",
    "Rules regarding labels format:\n",
    "\n",
    "    if label_mode is \"int\", the labels are an int32 tensor of shape (batch_size,).\n",
    "    if label_mode is \"binary\", the labels are a float32 tensor of 1s and 0s of shape (batch_size, 1).\n",
    "    if label_mode is \"categorical\", the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.\n",
    "\n",
    "Rules regarding number of channels in the yielded images:\n",
    "\n",
    "    if color_mode is \"grayscale\", there's 1 channel in the image tensors.\n",
    "    if color_mode is \"rgb\", there are 3 channels in the image tensors.\n",
    "    if color_mode is \"rgba\", there are 4 channels in the image tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_img function\n",
    "\n",
    "keras.utils.load_img(\n",
    "    path,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size=None,\n",
    "    interpolation=\"nearest\",\n",
    "    keep_aspect_ratio=False,\n",
    ")\n",
    "\n",
    "Loads an image into PIL format.\n",
    "\n",
    "Example\n",
    "\n",
    "image = keras.utils.load_img(image_path)\n",
    "input_arr = keras.utils.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = model.predict(input_arr)\n",
    "\n",
    "Arguments\n",
    "\n",
    "    path: Path to image file.\n",
    "    color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". The desired image format.\n",
    "    target_size: Either None (default to original size) or tuple of ints (img_height, img_width).\n",
    "    interpolation: Interpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3 or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0 or newer is installed, \"box\" and \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "    keep_aspect_ratio: Boolean, whether to resize images to a target size without aspect ratio distortion. The image is cropped in the center with target aspect ratio before resizing.\n",
    "\n",
    "Returns\n",
    "\n",
    "A PIL Image instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_to_array function\n",
    "\n",
    "keras.utils.img_to_array(img, data_format=None, dtype=None)\n",
    "\n",
    "Converts a PIL Image instance to a NumPy array.\n",
    "\n",
    "Example\n",
    "\n",
    "from PIL import Image\n",
    "img_data = np.random.random(size=(100, 100, 3))\n",
    "img = keras.utils.array_to_img(img_data)\n",
    "array = keras.utils.image.img_to_array(img)\n",
    "\n",
    "Arguments\n",
    "\n",
    "    img: Input PIL Image instance.\n",
    "    data_format: Image data format, can be either \"channels_first\" or \"channels_last\". Defaults to None, in which case the global setting keras.backend.image_data_format() is used (unless you changed it, it defaults to \"channels_last\").\n",
    "    dtype: Dtype to use. None means the global setting keras.backend.floatx() is used (unless you changed it, it defaults to \"float32\").\n",
    "\n",
    "Returns\n",
    "\n",
    "A 3D NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save_img function\n",
    "\n",
    "keras.utils.save_img(\n",
    "    path, x, data_format=None, file_format=None, scale=True, **kwargs\n",
    ")\n",
    "\n",
    "Saves an image stored as a NumPy array to a path or file object.\n",
    "\n",
    "Arguments\n",
    "\n",
    "    path: Path or file object.\n",
    "    x: NumPy array.\n",
    "    data_format: Image data format, either \"channels_first\" or \"channels_last\".\n",
    "    file_format: Optional file format override. If omitted, the format to use is determined from the filename extension. If a file object was used instead of a filename, this parameter should always be used.\n",
    "    scale: Whether to rescale image values to be within [0, 255].\n",
    "    **kwargs: Additional keyword arguments passed to PIL.Image.save().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### array_to_img function\n",
    "\n",
    "keras.utils.array_to_img(x, data_format=None, scale=True, dtype=None)\n",
    "\n",
    "Converts a 3D NumPy array to a PIL Image instance.\n",
    "\n",
    "Example\n",
    "\n",
    "from PIL import Image\n",
    "img = np.random.random(size=(100, 100, 3))\n",
    "pil_img = keras.utils.array_to_img(img)\n",
    "\n",
    "Arguments\n",
    "\n",
    "    x: Input data, in any form that can be converted to a NumPy array.\n",
    "    data_format: Image data format, can be either \"channels_first\" or \"channels_last\". Defaults to None, in which case the global setting keras.backend.image_data_format() is used (unless you changed it, it defaults to \"channels_last\").\n",
    "    scale: Whether to rescale the image such that minimum and maximum values are 0 and 255 respectively. Defaults to True.\n",
    "    dtype: Dtype to use. None means the global setting keras.backend.floatx() is used (unless you changed it, it defaults to \"float32\"). Defaults to None.\n",
    "\n",
    "Returns\n",
    "\n",
    "A PIL Image instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
